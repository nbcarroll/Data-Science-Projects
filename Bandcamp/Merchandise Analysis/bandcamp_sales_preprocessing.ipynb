{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>art_url</th>\n",
       "      <th>item_type</th>\n",
       "      <th>utc_date</th>\n",
       "      <th>country_code</th>\n",
       "      <th>track_album_slug_text</th>\n",
       "      <th>country</th>\n",
       "      <th>slug_type</th>\n",
       "      <th>amount_paid_fmt</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_description</th>\n",
       "      <th>art_id</th>\n",
       "      <th>url</th>\n",
       "      <th>amount_paid</th>\n",
       "      <th>releases</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>currency</th>\n",
       "      <th>album_title</th>\n",
       "      <th>amount_paid_usd</th>\n",
       "      <th>package_image_id</th>\n",
       "      <th>amount_over_fmt</th>\n",
       "      <th>item_slug</th>\n",
       "      <th>addl_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1599688803.5175&amp;//girlbanddublin.bandcamp.com/...</td>\n",
       "      <td>https://f4.bcbits.com/img/a0206405257_7.jpg</td>\n",
       "      <td>a</td>\n",
       "      <td>1599688803.517</td>\n",
       "      <td>gb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>a</td>\n",
       "      <td>$9.99</td>\n",
       "      <td>9.990</td>\n",
       "      <td>Live at Vicar Street</td>\n",
       "      <td>206405257.000</td>\n",
       "      <td>//girlbanddublin.bandcamp.com/album/live-at-vi...</td>\n",
       "      <td>9.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Girl Band</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1599688805.27838&amp;//maharettarecords.bandcamp.c...</td>\n",
       "      <td>https://f4.bcbits.com/img/a2984241552_7.jpg</td>\n",
       "      <td>a</td>\n",
       "      <td>1599688805.278</td>\n",
       "      <td>fi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finland</td>\n",
       "      <td>a</td>\n",
       "      <td>£1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Neurogen</td>\n",
       "      <td>2984241552.000</td>\n",
       "      <td>//maharettarecords.bandcamp.com/album/neurogen</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jirah</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1599688805.90646&amp;//maharettarecords.bandcamp.c...</td>\n",
       "      <td>https://f4.bcbits.com/img/a3320494770_7.jpg</td>\n",
       "      <td>a</td>\n",
       "      <td>1599688805.906</td>\n",
       "      <td>fi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finland</td>\n",
       "      <td>a</td>\n",
       "      <td>£3</td>\n",
       "      <td>3.000</td>\n",
       "      <td>The Last Snare Bender</td>\n",
       "      <td>3320494770.000</td>\n",
       "      <td>//maharettarecords.bandcamp.com/album/the-last...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D-Ther</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1599688806.94234&amp;//alicesitski.bandcamp.com/al...</td>\n",
       "      <td>https://f4.bcbits.com/img/0020476345_37.jpg</td>\n",
       "      <td>p</td>\n",
       "      <td>1599688806.942</td>\n",
       "      <td>gb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>a</td>\n",
       "      <td>€10.50</td>\n",
       "      <td>10.500</td>\n",
       "      <td>Limited Edition Compact Disc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>//alicesitski.bandcamp.com/album/white-noise-tv</td>\n",
       "      <td>10.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE NOISE TV</td>\n",
       "      <td>EUR</td>\n",
       "      <td>WHITE NOISE TV</td>\n",
       "      <td>12.390</td>\n",
       "      <td>20476345.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1599688809.07942&amp;//linguaignota.bandcamp.com/t...</td>\n",
       "      <td>https://f4.bcbits.com/img/a3428873396_7.jpg</td>\n",
       "      <td>t</td>\n",
       "      <td>1599688809.079</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>t</td>\n",
       "      <td>$1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>O Ruthless Great Divine Director</td>\n",
       "      <td>3428873396.000</td>\n",
       "      <td>//linguaignota.bandcamp.com/track/o-ruthless-g...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINGUA IGNOTA</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _id  \\\n",
       "0  1599688803.5175&//girlbanddublin.bandcamp.com/...   \n",
       "1  1599688805.27838&//maharettarecords.bandcamp.c...   \n",
       "2  1599688805.90646&//maharettarecords.bandcamp.c...   \n",
       "3  1599688806.94234&//alicesitski.bandcamp.com/al...   \n",
       "4  1599688809.07942&//linguaignota.bandcamp.com/t...   \n",
       "\n",
       "                                       art_url item_type       utc_date  \\\n",
       "0  https://f4.bcbits.com/img/a0206405257_7.jpg         a 1599688803.517   \n",
       "1  https://f4.bcbits.com/img/a2984241552_7.jpg         a 1599688805.278   \n",
       "2  https://f4.bcbits.com/img/a3320494770_7.jpg         a 1599688805.906   \n",
       "3  https://f4.bcbits.com/img/0020476345_37.jpg         p 1599688806.942   \n",
       "4  https://f4.bcbits.com/img/a3428873396_7.jpg         t 1599688809.079   \n",
       "\n",
       "  country_code track_album_slug_text         country slug_type  \\\n",
       "0           gb                   NaN  United Kingdom         a   \n",
       "1           fi                   NaN         Finland         a   \n",
       "2           fi                   NaN         Finland         a   \n",
       "3           gb                   NaN  United Kingdom         a   \n",
       "4           us                   NaN   United States         t   \n",
       "\n",
       "  amount_paid_fmt  item_price                  item_description  \\\n",
       "0           $9.99       9.990              Live at Vicar Street   \n",
       "1              £1       1.000                          Neurogen   \n",
       "2              £3       3.000             The Last Snare Bender   \n",
       "3          €10.50      10.500      Limited Edition Compact Disc   \n",
       "4              $1       1.000  O Ruthless Great Divine Director   \n",
       "\n",
       "          art_id                                                url  \\\n",
       "0  206405257.000  //girlbanddublin.bandcamp.com/album/live-at-vi...   \n",
       "1 2984241552.000     //maharettarecords.bandcamp.com/album/neurogen   \n",
       "2 3320494770.000  //maharettarecords.bandcamp.com/album/the-last...   \n",
       "3            NaN    //alicesitski.bandcamp.com/album/white-noise-tv   \n",
       "4 3428873396.000  //linguaignota.bandcamp.com/track/o-ruthless-g...   \n",
       "\n",
       "   amount_paid  releases     artist_name currency     album_title  \\\n",
       "0        9.990       NaN       Girl Band      USD             NaN   \n",
       "1        1.000       NaN           Jirah      GBP             NaN   \n",
       "2        3.000       NaN          D-Ther      GBP             NaN   \n",
       "3       10.500       NaN  WHITE NOISE TV      EUR  WHITE NOISE TV   \n",
       "4        1.000       NaN   LINGUA IGNOTA      USD             NaN   \n",
       "\n",
       "   amount_paid_usd  package_image_id amount_over_fmt item_slug  addl_count  \n",
       "0            9.990               NaN             NaN       NaN         NaN  \n",
       "1            1.300               NaN             NaN       NaN         NaN  \n",
       "2            3.900               NaN             NaN       NaN         NaN  \n",
       "3           12.390      20476345.000             NaN       NaN         NaN  \n",
       "4            1.000               NaN             NaN       NaN         NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Downloaded From: https://www.kaggle.com/datasets/mathurinache/1000000-bandcamp-sales\n",
    "\n",
    "# Importing Numerical Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option('display.max_row', None)\n",
    "pd.set_option('display.max_column', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Importing Visualization Packages\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# For Handling Times\n",
    "import pytz\n",
    "\n",
    "# Importing CSV\n",
    "df = pd.read_csv(r'C:\\Users\\nickb\\Documents\\SeattleU\\Fall 2022\\DataVisualization_BUAN5210\\Final Project\\1000000-bandcamp-sales.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     879253\n",
       "Yes    120747\n",
       "Name: Item Listed As Free, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing Item Names\n",
    "replace_item_type = {'a': 'Digital Album',\n",
    "'p': 'Physical Item',\n",
    "'t': 'Digital Track'}\n",
    "df = df.replace({\"item_type\": replace_item_type})\n",
    "\n",
    "# Renaming Columns for Clarity\n",
    "df.rename(columns = {'country':'Buyer Country',\n",
    "                     'releases':'Total Artist Releases'}, inplace = True)\n",
    "\n",
    "# Dropping Duplicate or Irrelevant Columns\n",
    "df.drop(['track_album_slug_text', 'country_code', 'art_id', '_id', 'art_url', 'url',\n",
    "         'package_image_id', 'Total Artist Releases', 'item_slug'], axis=1, inplace=True)\n",
    "\n",
    "# Renaming Columns for Clarity\n",
    "replace_dict = {'t': 'Digital Track', 'a': 'Digital & Physical Albums', 'p': 'Merchandise'}\n",
    "df['slug_type'].replace(replace_dict, inplace=True)\n",
    "\n",
    "\n",
    "# This is how I found out that b is equal to 'Full Digital Discography'. Same Descriptions more or less. Uncomment to run if you're curious.\n",
    "# full_dig = df.loc[(df['item_type'] == 'b')]\n",
    "# full_dig['item_description'].value_counts()\n",
    "\n",
    "# Imputting Value for 'Full Digital Discography'\n",
    "df.loc[(df['item_type'] == 'b'), 'item_type'] = 'Full Digital Discography'\n",
    "\n",
    "# Imputting Value for Physical Album\n",
    "df.loc[(df['item_type'] != 'Digital Album') & (df['slug_type'] == 'Digital & Physical Albums'), 'item_type'] = 'Physical Album'\n",
    "\n",
    "# Creating (Hopefully) Clearer Feature Names\n",
    "df.rename(columns={'amount_paid_fmt': 'Currency Symbol + Paid (In Seller Currency)',\n",
    "                   'item_price': 'Price (Seller Currency)',\n",
    "                   'amount_paid': 'Paid (Seller Currency)',\n",
    "                   'amount_paid_usd': 'Paid (US Dollars)',\n",
    "                   'slug_type': 'Item Category (Main)',\n",
    "                   'item_type': 'Item Category (Subcategory)',\n",
    "                   'amount_over_fmt': 'Paid OVER List Price (Seller Currency)',\n",
    "                   'artist_name': 'Artist/Label Name'\n",
    "                   }, inplace=True)\n",
    "\n",
    "# Creating a New Column that Returns 'Yes' if the input value is less than 0.000001, indicating that the price is effectively zero, otherwise returns 'No'.\n",
    "def no_price (value):\n",
    "   if value < 0.000001: \n",
    "      return 'Yes' # Done as Yes/No, so it doesn't auto turn this into a numerical measure\n",
    "   return 'No'\n",
    "\n",
    "df['Item Listed As Free'] = df['Price (Seller Currency)'].map(no_price)\n",
    "df['Item Listed As Free'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Rows Without Artist/Label Name\n",
    "df = df[df['Artist/Label Name'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Epoch Time to Time\n",
    "df['utc_date'] = pd.to_datetime(df['utc_date'],unit='s')\n",
    "\n",
    "# Converting Time to Pacific (Timezone Bandcamp Uses For Bandcamp Fridays)\n",
    "df['utc_date'] = df['utc_date'].dt.tz_localize('US/Pacific').dt.tz_convert('UTC')\n",
    "\n",
    "# Renaming Date as it's now Pacific Timezone\n",
    "df = df.rename({'utc_date': 'Date_Time_PT',}, axis=1) \n",
    "\n",
    "# Creating New Column for the Percentage a Buyer Paid Over the Seller's List Price on an Item\n",
    "df['Percent Paid Over List Price'] = ((df['Paid (Seller Currency)'] - df['Price (Seller Currency)']) / df['Price (Seller Currency)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing -0.000 and 0.000 with 0\n",
    "df['Percent Paid Over List Price'] = df['Percent Paid Over List Price'].replace([-0.000, 0.000], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a New Column Called Discount Code Applied if the Percent over List Price is less than 0, which assigns a value of Yes in that case\n",
    "def discount_code (value):\n",
    "    if value < -0.00001: \n",
    "        return 'Yes'\n",
    "    return 'No'\n",
    "\n",
    "df['Discount Code Applied'] = df['Percent Paid Over List Price'].map(discount_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Currency to Seller Currency\n",
    "df.rename(columns={'currency': 'Seller Currency'}, inplace=True)\n",
    "\n",
    "# Reordering Dataframe\n",
    "df = df[['Date_Time_PT', 'Item Category (Main)', 'Item Category (Subcategory)', 'item_description','Artist/Label Name', 'Buyer Country', 'Seller Currency','Currency Symbol + Paid (In Seller Currency)', 'Price (Seller Currency)', 'Paid (Seller Currency)', 'Paid (US Dollars)', 'Paid OVER List Price (Seller Currency)', 'Item Listed As Free', 'Percent Paid Over List Price']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over 100k of items had isna for paid over list price item, so recalculating colum. Uncomment next line to see.\n",
    "# df['Paid OVER List Price (Seller Currency)'].isna().value_counts()\n",
    "df['Paid OVER List Price (Seller Currency)'] = (df['Paid (Seller Currency)'] - df['Price (Seller Currency)'])\n",
    "\n",
    "# Rounding to Two Decimal Places, it seemed like some columns were not binning values correctly\n",
    "df['Paid OVER List Price (Seller Currency)'] = df['Paid OVER List Price (Seller Currency)'].round(decimals = 2)\n",
    "\n",
    "# Replace all the NaN Values which based on other columns can tell are 'Full Digital Discography\" with that\n",
    "df['Item Category (Main)'] = df['Item Category (Main)'].replace(np.NaN,'Full Digital Discography')\n",
    "\n",
    "# Gave More Accurate Name. There are EP's & Singles Shown Too.\n",
    "df.rename(columns={'album_title': 'Release Title'\n",
    "                   }, inplace=True)\n",
    "\n",
    "df['Percent Paid Over List Price'] = df['Percent Paid Over List Price'].round(decimals = 2)\n",
    "\n",
    "# Replacing Inifinite Values with NaN. This Way in Tableau, It Shows Datatype as Numeric\n",
    "df['Percent Paid Over List Price'] = df['Percent Paid Over List Price'].replace(np.inf, np.NaN)\n",
    "\n",
    "df['Bandcamp_Friday?'] = df['Date_Time_PT']\n",
    "# If on this date, then assign as Bandcamp Friday\n",
    "df.loc[(df['Date_Time_PT'] > '2020-10-02', \"Bandcamp_Friday?\")] = \"Yes\"\n",
    "\n",
    "# If on this date, then assign as NOT Bandcamp Friday\n",
    "df.loc[(df['Date_Time_PT'] < '2020-10-02', \"Bandcamp_Friday?\")] = \"No\"\n",
    "\n",
    "# Renaming to a more straightforward title\n",
    "df['Item Category (Main)'] = df['Item Category (Main)'].replace('Digital & Physical Albums', 'Albums & EP\\'s')\n",
    "\n",
    "# Replaces the value 'Digital & Physical Albums' with 'Albums & EP's' in the 'Item Category (Main)' column of the DataFrame 'df'\n",
    "df['Item Category (Main)'] = df['Item Category (Main)'].replace('Digital & Physical Albums', 'Albums & EP\\'s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside of item description there is a lot of information, that could be changed into it's own column.\n",
    "\n",
    "Also during this phase I found that a lot of albums that labels and artists had categorized as merchandise was actually physical releases. I was able to identify all of these different categories by slowly iterating through Merchandise that was classified as 'Other Merch' and seeing if I could identify larger categories. For example, 'Face Masks' were found as a result of doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Code Could Definitely be Cleaner, but it works. It's a bit of a mess, but it works.\n",
    "\n",
    "conditions = [\n",
    "    (df['Item Category (Subcategory)'] == 'Digital Album') | (df['Item Category (Subcategory)'] == 'Digital Track') | (df['Item Category (Subcategory)'] == 'Full Digital Discography'),\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('shirt', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Tee', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Baseball T', case=False, regex=True)), # Shirt\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('hoodie', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('sweater', case=False, regex=True)), # Hoodie\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Tote', case=False, regex=True)), # Tote Bag\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Patch', case=False, regex=True)), # Patches\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Mask', case=False, regex=True)), # Mask\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Bundle', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Pack', case=False, regex=True)) # Bundle... might contain vinyl too\n",
    "                                                  | (df['item_description'].str.contains(' Box', case=False, regex=True)) # Bundle... might contain vinyl too\n",
    "                                                  | (df['item_description'].str.contains('Swag', case=False, regex=True)), # Bundle... might contain vinyl too\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Cassette', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Tape', case=False, regex=True)), # Cassette\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('10\"', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('7\"', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains(' LP', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('12\"', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Repress', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('LP', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Vinyl', case=False, regex=True)), # Vinyl\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Sticker', case=False, regex=True)), # Sticker\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Longsleeve', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Long-Sleeve', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Long Sleeve', case=False, regex=True)), # Long-Sleeves\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Poster', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Print', case=False, regex=True)), # Poster\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Ticket', case=False, regex=True)), # Ticket\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Book', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Zine', case=False, regex=True))\n",
    "                                                  | (df['item_description'].str.contains('Paperback', case=False, regex=True)), # Books\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('CD', case=False, regex=True)) # CD\n",
    "                                                  | (df['item_description'].str.contains('Compact Disc', case=False, regex=True)), \n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Trucker Hat', case=False, regex=True)) |\n",
    "                                                    (df['item_description'].str.contains('Baseball Hat', case=False, regex=True)) |\n",
    "                                                    (df['item_description'].str.contains('hat', case=False, regex=True)) |\n",
    "                                                    (df['item_description'].str.contains('Beanie', case=False, regex=True)) |\n",
    "                                                    (df['item_description'].str.contains(' cap', case=False, regex=True)), # Hat\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Button', case=False, regex=True)) |\n",
    "                                                    (df['item_description'].str.contains('Pin', case=False, regex=True)),\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Pants', case=False, regex=True)),\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Towel', case=False, regex=True)),\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Scarf', case=False, regex=True)),\n",
    "    (df['Item Category (Main)'] == 'Merchandise') & (df['item_description'].str.contains('Robe', case=False, regex=True)),\n",
    "    (df['Item Category (Main)'] == 'Merchandise')] # Other Merch\n",
    "\n",
    "choices = ['Digital Music','Shirt', 'Hoodie','Tote Bag','Patch','Face Mask','Bundle','Cassette','Vinyl','Sticker','Long-Sleeve Shirts','Poster/Print','Tickets','Book','CD','Hats','Buttons/Pins','Pants','Towel','Scarves','Robes','Other Items']\n",
    "df['Merch_Category'] = np.select(conditions, choices, default='Not Merch')\n",
    "\n",
    "# Check item_description column and if it contains 'Stream' then assign 'Live Stream' to Merch_Category\n",
    "df['Merch_Category'] = np.where((df['item_description'].str.contains('live stream', case=False, regex=True)), 'Live Stream', df['Merch_Category'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Merchandise Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for Other Items\n",
    "df_other_items = df[(df['Merch_Category'] == 'Other Items')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While at first I was manually iterating through the dataframe and assessing new categories of items, this was taking longer than expected and there were still 10k items without clear categories. As such, I implemented Natural Language Processing to assist with further processing.\n",
    "While some values were found that were inconclusive such as 'Limited', which could apply to a variety of items, others such as 'Pack' and 'Bottle' had clearer categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-', 1805), ('The', 502), ('Edition', 438), ('Limited', 418), ('Live', 406), ('of', 381), ('the', 355), ('/', 323), ('&', 288), ('A', 285), ('2020', 265), ('USB', 246), ('by', 239), ('THE', 231), ('BOTTLE', 222), ('OPENER', 222), ('Your', 218), ('Logo', 197), ('Matmos', 191), ('Low-Cost-co', 191), ('Stream', 191), ('Dream!', 191), ('from', 184), ('Camiseta', 183), ('+', 182), ('Signed', 182), ('From', 172), ('Mug', 171), ('for', 156), ('Issue', 152), ('Cheki', 152), ('T', 152), ('OF', 148), ('Batch', 141), ('2', 137), ('to', 129), ('Private', 126), ('OUT', 122), ('|', 121), ('with', 120), ('DARKNESS', 120), ('*Pre-Order*', 117), ('Document', 117), ('Culture', 117), ('Pamphlet', 117), ('CXT002', 117), ('on', 116), ('x', 115), ('VOTE!', 115), ('BIDEN', 115), ('HARRIS', 115), ('Black', 114), ('Joan', 114), ('Shelley', 114), ('Camp', 114), ('Ample', 114), ('Branch', 114), ('1', 112), ('PREORDER', 111), ('I', 108), ('New', 107), ('DVD', 105), ('Music', 104), ('Fall', 102), ('Flag', 100), ('Card', 99), ('Matthew', 97), ('#1', 96), ('a', 94), ('Of', 92), ('Drive', 91), ('3', 90), ('Slipmat', 90), ('Home', 90), ('SOUND', 90), ('09/12', 85), ('EP', 85), ('(Limited', 85), ('\"The', 84), ('Dr.', 84), ('and', 83), ('in', 82), ('Lost', 81), ('Theory', 81), ('Guitar', 80), ('Compleat', 80), ('Highland', 80), ('Bagpipe,', 80), ('Welch', 80), ('Paradise', 77), ('BLACK', 76), ('Floppy', 74), ('GHOST', 74), ('?', 74), ('You', 73), ('Tip', 73), ('de', 72), ('PILLS', 72), ('Oct', 72), ('rip', 72)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickb\\AppData\\Local\\Temp\\ipykernel_41840\\820680613.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_other_items['Merch_Category_Processed'] = df_other_items['item_description'].apply(lambda x: ' '.join([word.lower() for word in word_tokenize(x) if (word.isalpha()) and (word.lower() not in stopwords)]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "df_other_items['Merch_Category_Processed'] = df_other_items['item_description'].apply(lambda x: ' '.join([word.lower() for word in word_tokenize(x) if (word.isalpha()) and (word.lower() not in stopwords)]))\n",
    "\n",
    "fdist = FreqDist()\n",
    "for row in df_other_items['item_description']:\n",
    "    for word in row.split():\n",
    "        fdist[word] += 1\n",
    "\n",
    "top_words = fdist.most_common(100)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check item_description for na values\n",
    "df['item_description'].fillna('No Description', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show only  the rows where the item category is 'Merchandise' and the merch Category is Vinyl. Take these rows and change the item category main to Albums & EP's\n",
    "df.loc[(df['Item Category (Main)'] == 'Merchandise') & (df['Merch_Category'] == 'Vinyl'), 'Item Category (Main)'] = 'Albums & EP\\'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called New_Main_Category and set it to the value of Item Category (Main)\n",
    "df['New_Main_Category'] = df['Item Category (Main)']\n",
    "\n",
    "# Take all the Digital Tracks and Full Digital Disography and Album & EP's and change the New_Main_Category to Digital Music\n",
    "df.loc[(df['Item Category (Main)'] == 'Digital Tracks') | (df['Item Category (Main)'] == 'Full Digital Discography') | (df['Item Category (Main)'] == 'Albums & EPs'), 'New_Main_Category'] = 'Digital Music'\n",
    "\n",
    "# Select Only Rows that For Item Subcategory is Digital Album and rename the New_Main_Category for these rows to Digital Music\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Digital Album'), 'New_Main_Category'] = 'Digital Music'\n",
    "\n",
    "# Select Only Rows that For Item Subcategory is Digital Track and rename the New_Main_Category for these rows to Digital Music\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Digital Track'), 'New_Main_Category'] = 'Digital Music'\n",
    "\n",
    "# Select Only Rows that For Item Subcategory is Physical Album and rename the New_Main_Category for these rows to Physical Music\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Physical Album'), 'New_Main_Category'] = 'Physical Music'\n",
    "\n",
    "# Show Only Rows that for Merch_Category has Vinyl and rename the new_main_category to Physical Music\n",
    "df.loc[(df['Merch_Category'] == 'Vinyl'), 'New_Main_Category'] = 'Physical Music'\n",
    "\n",
    "# Show only rows that in item_desription \"digipack\" or \"Digipak\" is present and doesn't say \"Bundle\" and for Merch_Category make it say CD\n",
    "df.loc[(df['item_description'].str.contains('digipack', case=False, regex=True)) | (df['item_description'].str.contains('Digipak', case=False, regex=True)) & (df['Merch_Category'] != 'Bundle'), 'Merch_Category'] = 'CD'\n",
    "\n",
    "# Show only rows that for merch category is 'Tickets' or 'Live Stream' and rename the new main category to 'Tickets'\n",
    "df.loc[(df['Merch_Category'] == 'Tickets') | (df['Merch_Category'] == 'Live Stream'), 'New_Main_Category'] = 'Tickets'\n",
    "\n",
    "# Rename New_Main_Category to New_Category_Level_1\n",
    "df.rename(columns={'New_Main_Category': 'New_Category_Level_1'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating New_Category_Level_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a New Column Called New_Category_Level_2 and fill with null values\n",
    "df['New_Category_Level_2'] = np.nan\n",
    "\n",
    "# Create a new column called 'New_Category_Level_3' and set all the values to null\n",
    "df['New_Category_Level_3'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If in Item Category (Subcategory) is 'Digital Album', then set New_Category_Level_2 to 'Albums & EPs'\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Digital Album'), 'New_Category_Level_2'] = 'Albums & EPs'\n",
    "\n",
    "# If in Item Category (Subcategory) is 'Digital Track', then set New_Category_Level_2 to 'Individiual Track'\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Digital Track'), 'New_Category_Level_2'] = 'Individiual Track'\n",
    "\n",
    "# If in Item Category (Subcategory) is 'Digital Discography', then set New_Category_Level_2 to 'Full Digital Discography'\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Digital Discography'), 'New_Category_Level_2'] = 'Full Digital Discography'\n",
    "\n",
    "# If in Merch Category is 'CD', then set New_Category_Level_2 to 'CD'\n",
    "df.loc[(df['Merch_Category'] == 'CD'), 'New_Category_Level_2'] = 'CD'\n",
    "\n",
    "#If in Merch Category is 'Vinyl', then set New_Category_Level_2 to 'Vinyl'\n",
    "df.loc[(df['Merch_Category'] == 'Vinyl'), 'New_Category_Level_2'] = 'Vinyl'\n",
    "\n",
    "#If in Merch Category is 'Shirt' or 'Long-Sleeve Shirts' then set New_Category_Level_2 to 'Tops'\n",
    "df.loc[(df['Merch_Category'] == 'Shirt') | (df['Merch_Category'] == 'Long-Sleeve Shirts'), 'New_Category_Level_2'] = 'Tops'\n",
    "\n",
    "# If in Merch Category is 'Hoodie' or 'Sweatshirt' then set New_Category_Level_2 to 'Outerwear'\n",
    "df.loc[(df['Merch_Category'] == 'Hoodie') | (df['Merch_Category'] == 'Sweatshirt'), 'New_Category_Level_2'] = 'Outerwear'\n",
    "\n",
    "#If in Merch Category is 'Hat' or 'Beanie' or 'Patch' or 'Tote Bag' then set New_Category_Level_2 to 'Accessories'\n",
    "df.loc[(df['Merch_Category'] == 'Hat') | (df['Merch_Category'] == 'Beanie') | (df['Merch_Category'] == 'Patch') | (df['Merch_Category'] == 'Tote Bag'), 'New_Category_Level_2'] = 'Accessories'\n",
    "\n",
    "#If in Merch Category is 'Patch' or 'BUttons or Pins or Face Masks then set New_Category_Level_2 to 'Accessories'\n",
    "df.loc[(df['Merch_Category'] == 'Patch') | (df['Merch_Category'] == 'Buttons/Pins') | (df['Merch_Category'] == 'Face Mask'), 'New_Category_Level_2'] = 'Accessories'\n",
    "\n",
    "# If IN Merch Category its Poster/Print or Book then set New_Category_Level_2 to 'Prints & Books'\n",
    "df.loc[(df['Merch_Category'] == 'Poster/Print') | (df['Merch_Category'] == 'Book'), 'New_Category_Level_2'] = 'Prints & Books'\n",
    "\n",
    "# If IN Merch Category its Towel then set New_Category_Level_2 to Accessories\n",
    "df.loc[(df['Merch_Category'] == 'Towel'), 'New_Category_Level_2'] = 'Accessories'\n",
    "\n",
    "# If in Item Category (Subcategory) is 'Full Digital Discography' then set New_Category_Level_2 to 'Full Digital Discography'\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Full Digital Discography'), 'New_Category_Level_2'] = 'Full Digital Discography'\n",
    "\n",
    "#If in In item_description the word 'Cassette' is present then set New_Category_Level_2 to 'Cassette'\n",
    "df.loc[(df['item_description'].str.contains('Cassette', case=False, regex=True)), 'New_Category_Level_2'] = 'Cassette'\n",
    "\n",
    "#If in In item_description the word 'CD' is present then set New_Category_Level_2 to 'CD'\n",
    "df.loc[(df['item_description'].str.contains('CD', case=False, regex=True)), 'New_Category_Level_2'] = 'CD\\'s'\n",
    "\n",
    "# If in Item_Descrption 7” or 10” or 12” is present then set New_Category_Level_2 to 'Vinyl'\n",
    "df.loc[(df['item_description'].str.contains('7\"', case=False, regex=True)) | (df['item_description'].str.contains('10\"', case=False, regex=True)) | (df['item_description'].str.contains('12\"', case=False, regex=True)), 'New_Category_Level_2'] = 'Vinyl'\n",
    "\n",
    "#If in item_description the phrase \"Picture Disc\" is present then set New_Category_Level_2 to 'Vinyl'\n",
    "df.loc[(df['item_description'].str.contains('Picture Disc', case=False, regex=True)), 'New_Category_Level_2'] = 'Vinyl'\n",
    "\n",
    "# If in item_description \"3xLP\" or \"2xLP\" or \"4xLP\" or \"5xLP\" or \"6xLP\" or \"7xLP\" or \"8xLP\" or \"9xLP\" or \"10xLP\" is present then set New_Category_Level_2 to 'Vinyl'\n",
    "df.loc[(df['item_description'].str.contains('3xLP', case=False, regex=True)) | (df['item_description'].str.contains('2xLP', case=False, regex=True)) | (df['item_description'].str.contains('4xLP', case=False, regex=True)) | (df['item_description'].str.contains('5xLP', case=False, regex=True)) | (df['item_description'].str.contains('6xLP', case=False, regex=True)) | (df['item_description'].str.contains('7xLP', case=False, regex=True)) | (df['item_description'].str.contains('8xLP', case=False, regex=True)) | (df['item_description'].str.contains('9xLP', case=False, regex=True)) | (df['item_description'].str.contains('10xLP', case=False, regex=True)), 'New_Category_Level_2'] = 'Vinyl'\n",
    "\n",
    "# If \"earrings\" appears in the item_description then for New_Category_Level_2 set to 'Accessories'\n",
    "df.loc[(df['item_description'].str.contains('earrings', case=False, regex=True)), 'New_Category_Level_2'] = 'Accessories'\n",
    "\n",
    "# where item_description contains Ableton then set New_Category_Level_2 to 'Merchandise' and New_Category_level_3 to 'Music Software Plug-In\\s'\n",
    "df.loc[(df['item_description'].str.contains('Ableton', case=False, regex=True)), 'New_Category_Level_2'] = 'Merchandise'\n",
    "df.loc[(df['item_description'].str.contains('Ableton', case=False, regex=True)), 'New_Category_Level_3'] = 'Music Software Plug-In\\s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows where item_description contains \"10 inch\" or \"7 inch\" or \"12 inch\" and classify New_Category_Level_2 as 'Vinyl'\n",
    "df.loc[(df['item_description'].str.contains('10 inch', case=False, regex=True)) | (df['item_description'].str.contains('7 inch', case=False, regex=True)) | (df['item_description'].str.contains('12 inch', case=False, regex=True)), 'New_Category_Level_2'] = 'Vinyl'\n",
    "\n",
    "# rows where item category (subcategory) is 'Physical Album' and 'New_categry_level_2' is null amd Merch Category is 'Cassette' and classify New_Category_Level_2 as 'Cassette'\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Physical Album') & (df['New_Category_Level_2'].isna()) & (df['Merch_Category'] == 'Cassette'), 'New_Category_Level_2'] = 'Cassette'\n",
    "\n",
    "# rows where item category (subcategory) is 'Physical Album' and 'New_categry_level_2' is null amd Merch Category is 'Hats' and classify New_Category_Level_2 as 'Accessories'\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Physical Album') & (df['New_Category_Level_2'].isna()) & (df['Merch_Category'] == 'Hats'), 'New_Category_Level_2'] = 'Accessories'\n",
    "\n",
    "# rows where item category (subcategory) is 'Physical Album' and 'New_categry_level_2' is null amd Merch Category is 'Bundle' and 'item_descrption' does not contain 'featuring' or 'CD' or 'with' or'VHS' or \"+\" or \"inclujding\" and classify New_Category_Level_2 as 'Vinyl'\n",
    "df.loc[(df['Item Category (Subcategory)'] == 'Physical Album') & (df['New_Category_Level_2'].isna()) & (df['Merch_Category'] == 'Bundle') & (df['item_description'].str.contains('featuring', case=False, regex=True) == False) & (df['item_description'].str.contains('CD', case=False, regex=True) == False) & (df['item_description'].str.contains('with', case=False, regex=True) == False) & (df['item_description'].str.contains('VHS', case=False, regex=True) == False) & (df['item_description'].str.contains('\\+', case=False, regex=True) == False) & (df['item_description'].str.contains('including', case=False, regex=True) == False), 'New_Category_Level_2'] = 'Vinyl'\n",
    "\n",
    "# Get a count of the rows where in item_description the word \"flannel\" and either \"large\" or \"medium\" or \"small\" or \"XL\" or \"XS\" is present and for New_Category_Level_2 set to 'Tops'\n",
    "df.loc[(df['item_description'].str.contains('flannel', case=False, regex=True)) & (df['item_description'].str.contains('large', case=False, regex=True)) | (df['item_description'].str.contains('medium', case=False, regex=True)) | (df['item_description'].str.contains('small', case=False, regex=True)) | (df['item_description'].str.contains('XL', case=False, regex=True)) | (df['item_description'].str.contains('XS', case=False, regex=True)), 'New_Category_Level_2'] = 'Tops'\n",
    "\n",
    "# for Rows where in item_description the phrase \"TEST PRESSING\" is present and set New_Category_Level_2 to 'Vinyl'\n",
    "df.loc[(df['item_description'].str.contains('TEST PRESSING', case=False, regex=True)), 'New_Category_Level_2'] = 'Vinyl'\n",
    "\n",
    "# Get a count of rows where Double 45 is present in item_description and set New_Category_Level_2 to 'Vinyl'\n",
    "df.loc[(df['item_description'].str.contains('Double 45', case=False, regex=True)), 'New_Category_Level_2'] = 'Vinyl'\n",
    "\n",
    "# Get a Count of rows where in item_description the word \" sticker\" is found\n",
    "df.loc[(df['item_description'].str.contains('sticker', case=False, regex=True)), 'New_Category_Level_2'] = 'Accessories'\n",
    "\n",
    "# Get the count of the number of rows where in item_description the word \" sticker\" is found but the symbols + or & or the words \"and\" or \"pack\" or \"bundle\" are not found and set New_Category_Level_2 to 'Accessories'\n",
    "df.loc[(df['item_description'].str.contains('sticker', case=False, regex=True)) & ~(df['item_description'].str.contains('\\+', case=False, regex=True)) & ~(df['item_description'].str.contains('&', case=False, regex=True)) & ~(df['item_description'].str.contains('and', case=False, regex=True)) & ~(df['item_description'].str.contains('pack', case=False, regex=True)) & ~(df['item_description'].str.contains('bundle', case=False, regex=True)), 'New_Category_Level_2'] = 'Accessories'\n",
    "\n",
    "# Show only the rows where New_Category_Level_2 is null and in item_descrption the words \"pack or \"bundle\" are present and for New_Category_Level_2 set to 'Bundles'\n",
    "df.loc[(df['New_Category_Level_2'].isna()) & (df['item_description'].str.contains('pack', case=False, regex=True)) | (df['item_description'].str.contains('bundle', case=False, regex=True)), 'New_Category_Level_2'] = 'Bundles'\n",
    "\n",
    "# If \" Tape\" appears in the item_description then for New_Category_Level_2 set to 'Cassettes'\n",
    "df.loc[(df['item_description'].str.contains(' Tape', case=False, regex=True)), 'New_Category_Level_2'] = 'Cassettes'\n",
    "\n",
    "# Show Only Rows where  C31\tis present in item_description and assign new_main_category 2 to 'Cassette'\n",
    "df.loc[(df['item_description'].str.contains('C31', case=False, regex=True)), 'New_Category_Level_2'] = 'Cassette'\n",
    "\n",
    "# Create an empty column called 'New Category Level 4'\n",
    "df['New_Category_Level_4'] = ''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Column for the Artist or Label's Currency\n",
    "This will be useful later when merging on the Discogs database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_country_dict = {\n",
    "    'USD': 'United States',\n",
    "    'GBP': 'United Kingdom',\n",
    "    'EUR': 'European Union',\n",
    "    'AUD': 'Australia',\n",
    "    'JPY': 'Japan',\n",
    "    'SEK': 'Sweden',\n",
    "    'CAD': 'Canada',\n",
    "    'CZK': 'Czech Republic',\n",
    "    'NZD': 'New Zealand',\n",
    "    'DKK': 'Denmark',\n",
    "    'CHF': 'Switzerland',\n",
    "    'ILS': 'Israel',\n",
    "    'HUF': 'Hungary',\n",
    "    'PLN': 'Poland',\n",
    "    'NOK': 'Norway',\n",
    "    'MXN': 'Mexico',\n",
    "    'HKD': 'Hong Kong',\n",
    "    'SGD': 'Singapore'\n",
    "}\n",
    "\n",
    "# function to map currency to country\n",
    "def map_currency_to_country(currency):\n",
    "    if currency in currency_country_dict:\n",
    "        return currency_country_dict[currency]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# create a new column called \"Artist/Label Country\"\n",
    "df['Artist/Label Country'] = ''\n",
    "\n",
    "# iterate through each row and map currency to country\n",
    "for index, row in df.iterrows():\n",
    "    currency = row['Seller Currency']\n",
    "    country = map_currency_to_country(currency)\n",
    "    df.at[index, 'Artist/Label Country'] = country\n",
    "\n",
    "# Create a New Column Called 'Buyer/Seller Country Match' and if for a given row the artist/label country is equal to the Buyer Country then set it to yes\n",
    "df['Buyer/Seller Country Match'] = np.where(df['Artist/Label Country'] == df['Buyer Country'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in 'Artist/Label Name':  159747\n",
      "Only  4.96 % of the artists and labels on the site are selling merchandise.\n"
     ]
    }
   ],
   "source": [
    "# Show Only the Count of Distinct Artists/Labels where New_Category_Level_1 is 'Merchandise'\n",
    "distinct_artists_labels_selling_merch = df['Artist/Label Name'].loc[(df['New_Category_Level_1'] == 'Merchandise')].nunique()\n",
    "\n",
    "# Count of the Distinct Artist/Label Names\n",
    "distinct_artists_labels = df['Artist/Label Name'].nunique()\n",
    "print(\"Number of distinct values in 'Artist/Label Name': \", distinct_artists_labels)\n",
    "\n",
    "print(\"Only \",round((distinct_artists_labels_selling_merch / distinct_artists_labels) * 100,2),\"% of the artists and labels on the site are selling merchandise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For rows where in merch_category it says 'Tote Bag', 'Face Mask','Hats', 'Sticker', 'Book', 'Buttons/Pins', 'Towel', 'Scarves', 'Pants', assign those column values to New_Category_Level_3 for that row\n",
    "df.loc[(df['Merch_Category'] == 'Tote Bag'), 'New_Category_Level_3'] = 'Tote Bags'\n",
    "df.loc[(df['Merch_Category'] == 'Face Mask'), 'New_Category_Level_3'] = 'Face Masks'\n",
    "df.loc[(df['Merch_Category'] == 'Hats'), 'New_Category_Level_3'] = 'Hats'\n",
    "df.loc[(df['Merch_Category'] == 'Sticker'), 'New_Category_Level_3'] = 'Stickers'\n",
    "df.loc[(df['Merch_Category'] == 'Book'), 'New_Category_Level_3'] = 'Books'\n",
    "df.loc[(df['Merch_Category'] == 'Buttons/Pins'), 'New_Category_Level_3'] = 'Buttons/Pins'\n",
    "df.loc[(df['Merch_Category'] == 'Towel'), 'New_Category_Level_3'] = 'Towels'\n",
    "df.loc[(df['Merch_Category'] == 'Scarves'), 'New_Category_Level_3'] = 'Scarves'\n",
    "df.loc[(df['Merch_Category'] == 'Pants'), 'New_Category_Level_3'] = 'Pants'\n",
    "df.loc[(df['Merch_Category'] == 'Patch'), 'New_Category_Level_3'] = 'Patches'\n",
    "df.loc[(df['Merch_Category'] == 'Shirt'), 'New_Category_Level_3'] = 'Shirt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting New_Category_Level 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Show Rows where New Category Level 3 is 'Shirt' and in item_description it says either 'T-Shirt' or 'Tee'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Shirt') & (df['item_description'].str.contains('T-Shirt', case=False, regex=True)) | (df['item_description'].str.contains('Tee', case=False, regex=True)) & ~(df['item_description'].str.contains('\\+', case=False, regex=True)), 'New_Category_Level_4'] = 'T-Shirt'\n",
    "\n",
    "# Only Show Rows where New Category Level 3 is 'Shirt' and New_Category_Level_4 is null\n",
    "df.loc[(df['New_Category_Level_3'] == 'Shirt') & (df['New_Category_Level_4'].isna()), 'New_Category_Level_4'] = 'Other Shirts'\n",
    "\n",
    "# If Merch_Catgory_Level_3 is tote bag then set New Category Level 4 to 'Tote Bag'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Tote Bags'), 'New_Category_Level_4'] = 'Tote Bags'\n",
    "\n",
    "# If Merch_Catgory_Level_3 is Face Mask then set New Category Level 4 to 'Face Mask'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Face Masks'), 'New_Category_Level_4'] = 'Face Masks'\n",
    "\n",
    "# If Merch_Catgory_Level_3 is Sticker then set New Category Level 4 to 'Sticker'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Stickers'), 'New_Category_Level_4'] = 'Stickers'\n",
    "\n",
    "# If Merch_Catgory_Level_3 is Button then set New Category Level 4 to 'Button'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Buttons/Pins'), 'New_Category_Level_4'] = 'Buttons/Pins'\n",
    "\n",
    "# If Merch_Catgory_Level_3 is Towel then set New Category Level 4 to 'Towel'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Towels'), 'New_Category_Level_4'] = 'Towels'\n",
    "\n",
    "# If Merch_Catgory_Level_3 is Scarf then set New Category Level 4 to 'Scarf'    \n",
    "df.loc[(df['New_Category_Level_3'] == 'Scarves'), 'New_Category_Level_4'] = 'Scarves'\n",
    "\n",
    "# If Merch_Catgory_Level_3 is Pants then set New Category Level 4 to 'Pants'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Pants'), 'New_Category_Level_4'] = 'Pants'\n",
    "\n",
    "# If Merch_Catgory_Level_3 is Patch then set New Category Level 4 to 'Patch'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Patches'), 'New_Category_Level_4'] = 'Patches'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Better Time Column for Tableau + Exporting To Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to convert a single date to ISO 8601 format\n",
    "def convert_to_iso(date):\n",
    "    return date.isoformat()\n",
    "\n",
    "# apply the function to each value in the 'date' column using apply()\n",
    "df['iso_date'] = df['Date_Time_PT'].apply(convert_to_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Digital Music         764110\n",
       "Vinyl                 101878\n",
       "Not Merch              63187\n",
       "Shirt                  21955\n",
       "CD                     17796\n",
       "Other Items             9536\n",
       "Bundle                  4797\n",
       "Cassette                4597\n",
       "Poster/Print            2048\n",
       "Hoodie                  1673\n",
       "Patch                   1412\n",
       "Long-Sleeve Shirts      1373\n",
       "Buttons/Pins            1370\n",
       "Book                    1134\n",
       "Hats                     906\n",
       "Face Mask                732\n",
       "Sticker                  655\n",
       "Tote Bag                 433\n",
       "Tickets                  242\n",
       "Live Stream               71\n",
       "Towel                     43\n",
       "Scarves                   41\n",
       "Robes                      6\n",
       "Pants                      3\n",
       "Name: Merch_Category, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Merch_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time_PT</th>\n",
       "      <th>Item Category (Main)</th>\n",
       "      <th>Item Category (Subcategory)</th>\n",
       "      <th>item_description</th>\n",
       "      <th>Artist/Label Name</th>\n",
       "      <th>Buyer Country</th>\n",
       "      <th>Seller Currency</th>\n",
       "      <th>Currency Symbol + Paid (In Seller Currency)</th>\n",
       "      <th>Price (Seller Currency)</th>\n",
       "      <th>Paid (Seller Currency)</th>\n",
       "      <th>Paid (US Dollars)</th>\n",
       "      <th>Paid OVER List Price (Seller Currency)</th>\n",
       "      <th>Item Listed As Free</th>\n",
       "      <th>Percent Paid Over List Price</th>\n",
       "      <th>Bandcamp_Friday?</th>\n",
       "      <th>Merch_Category</th>\n",
       "      <th>New_Category_Level_1</th>\n",
       "      <th>New_Category_Level_2</th>\n",
       "      <th>New_Category_Level_3</th>\n",
       "      <th>New_Category_Level_4</th>\n",
       "      <th>Artist/Label Country</th>\n",
       "      <th>Buyer/Seller Country Match</th>\n",
       "      <th>iso_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2020-09-10 05:16:36.737009920+00:00</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>Physical Item</td>\n",
       "      <td>Baba Naga Robe</td>\n",
       "      <td>Baba Naga</td>\n",
       "      <td>France</td>\n",
       "      <td>GBP</td>\n",
       "      <td>£10</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>12.990</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>Robes</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-09-10T05:16:36.737009920+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94398</th>\n",
       "      <td>2020-09-12 07:13:13.224069888+00:00</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>Physical Item</td>\n",
       "      <td>Spring - a poetry pamphlet by Fay Roberts</td>\n",
       "      <td>Allographic Press</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GBP</td>\n",
       "      <td>£5</td>\n",
       "      <td>3.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.400</td>\n",
       "      <td>1.500</td>\n",
       "      <td>No</td>\n",
       "      <td>0.430</td>\n",
       "      <td>No</td>\n",
       "      <td>Robes</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2020-09-12T07:13:13.224069888+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127585</th>\n",
       "      <td>2020-09-13 01:41:35.397959936+00:00</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>Physical Item</td>\n",
       "      <td>Strobe - deadmau5 (Guitar tab en pdf / .gp5)</td>\n",
       "      <td>El Profe Mauro</td>\n",
       "      <td>Germany</td>\n",
       "      <td>USD</td>\n",
       "      <td>$5.99</td>\n",
       "      <td>5.990</td>\n",
       "      <td>5.990</td>\n",
       "      <td>5.990</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>Robes</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-09-13T01:41:35.397959936+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202929</th>\n",
       "      <td>2020-09-15 05:11:35.803020032+00:00</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>Physical Item</td>\n",
       "      <td>Strobe - deadmau5 (Guitar tab en pdf / .gp5)</td>\n",
       "      <td>El Profe Mauro</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>USD</td>\n",
       "      <td>$5.99</td>\n",
       "      <td>5.990</td>\n",
       "      <td>5.990</td>\n",
       "      <td>5.990</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>Robes</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-09-15T05:11:35.803020032+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702234</th>\n",
       "      <td>2020-09-27 04:58:28.875379968+00:00</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>Physical Item</td>\n",
       "      <td>Corridor by Jonathan Robert</td>\n",
       "      <td>Corridor</td>\n",
       "      <td>Canada</td>\n",
       "      <td>USD</td>\n",
       "      <td>$18</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>Robes</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>2020-09-27T04:58:28.875379968+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930456</th>\n",
       "      <td>2020-10-02 15:53:07.162450176+00:00</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>Physical Item</td>\n",
       "      <td>Genuflection Robe Black/Gold</td>\n",
       "      <td>Baba Naga</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GBP</td>\n",
       "      <td>£15</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>19.290</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Robes</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2020-10-02T15:53:07.162450176+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Date_Time_PT Item Category (Main)  \\\n",
       "544    2020-09-10 05:16:36.737009920+00:00          Merchandise   \n",
       "94398  2020-09-12 07:13:13.224069888+00:00          Merchandise   \n",
       "127585 2020-09-13 01:41:35.397959936+00:00          Merchandise   \n",
       "202929 2020-09-15 05:11:35.803020032+00:00          Merchandise   \n",
       "702234 2020-09-27 04:58:28.875379968+00:00          Merchandise   \n",
       "930456 2020-10-02 15:53:07.162450176+00:00          Merchandise   \n",
       "\n",
       "       Item Category (Subcategory)  \\\n",
       "544                  Physical Item   \n",
       "94398                Physical Item   \n",
       "127585               Physical Item   \n",
       "202929               Physical Item   \n",
       "702234               Physical Item   \n",
       "930456               Physical Item   \n",
       "\n",
       "                                    item_description  Artist/Label Name  \\\n",
       "544                                   Baba Naga Robe          Baba Naga   \n",
       "94398      Spring - a poetry pamphlet by Fay Roberts  Allographic Press   \n",
       "127585  Strobe - deadmau5 (Guitar tab en pdf / .gp5)     El Profe Mauro   \n",
       "202929  Strobe - deadmau5 (Guitar tab en pdf / .gp5)     El Profe Mauro   \n",
       "702234                   Corridor by Jonathan Robert           Corridor   \n",
       "930456                  Genuflection Robe Black/Gold          Baba Naga   \n",
       "\n",
       "         Buyer Country Seller Currency  \\\n",
       "544             France             GBP   \n",
       "94398   United Kingdom             GBP   \n",
       "127585         Germany             USD   \n",
       "202929  United Kingdom             USD   \n",
       "702234          Canada             USD   \n",
       "930456  United Kingdom             GBP   \n",
       "\n",
       "       Currency Symbol + Paid (In Seller Currency)  Price (Seller Currency)  \\\n",
       "544                                            £10                   10.000   \n",
       "94398                                           £5                    3.500   \n",
       "127585                                       $5.99                    5.990   \n",
       "202929                                       $5.99                    5.990   \n",
       "702234                                         $18                   18.000   \n",
       "930456                                         £15                   15.000   \n",
       "\n",
       "        Paid (Seller Currency)  Paid (US Dollars)  \\\n",
       "544                     10.000             12.990   \n",
       "94398                    5.000              6.400   \n",
       "127585                   5.990              5.990   \n",
       "202929                   5.990              5.990   \n",
       "702234                  18.000             18.000   \n",
       "930456                  15.000             19.290   \n",
       "\n",
       "        Paid OVER List Price (Seller Currency) Item Listed As Free  \\\n",
       "544                                      0.000                  No   \n",
       "94398                                    1.500                  No   \n",
       "127585                                   0.000                  No   \n",
       "202929                                   0.000                  No   \n",
       "702234                                   0.000                  No   \n",
       "930456                                   0.000                  No   \n",
       "\n",
       "        Percent Paid Over List Price Bandcamp_Friday? Merch_Category  \\\n",
       "544                            0.000               No          Robes   \n",
       "94398                          0.430               No          Robes   \n",
       "127585                         0.000               No          Robes   \n",
       "202929                         0.000               No          Robes   \n",
       "702234                         0.000               No          Robes   \n",
       "930456                         0.000              Yes          Robes   \n",
       "\n",
       "       New_Category_Level_1 New_Category_Level_2 New_Category_Level_3  \\\n",
       "544             Merchandise                  NaN                  NaN   \n",
       "94398           Merchandise                  NaN                  NaN   \n",
       "127585          Merchandise                  NaN                  NaN   \n",
       "202929          Merchandise                  NaN                  NaN   \n",
       "702234          Merchandise                  NaN                  NaN   \n",
       "930456          Merchandise                  NaN                  NaN   \n",
       "\n",
       "       New_Category_Level_4 Artist/Label Country Buyer/Seller Country Match  \\\n",
       "544                               United Kingdom                         No   \n",
       "94398                             United Kingdom                        Yes   \n",
       "127585                             United States                         No   \n",
       "202929                             United States                         No   \n",
       "702234                             United States                         No   \n",
       "930456                            United Kingdom                        Yes   \n",
       "\n",
       "                                   iso_date  \n",
       "544     2020-09-10T05:16:36.737009920+00:00  \n",
       "94398   2020-09-12T07:13:13.224069888+00:00  \n",
       "127585  2020-09-13T01:41:35.397959936+00:00  \n",
       "202929  2020-09-15T05:11:35.803020032+00:00  \n",
       "702234  2020-09-27T04:58:28.875379968+00:00  \n",
       "930456  2020-10-02T15:53:07.162450176+00:00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show only rows where Merch_Category is Robes...\n",
    "df.loc[(df['Merch_Category'] == 'Robes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Merch_Category is Hats then set New Category Level 4 to 'Hats'\n",
    "df.loc[(df['New_Category_Level_3'] == 'Hats'), 'New_Category_Level_4'] = 'Hats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                976460\n",
       "T-Shirt          17943\n",
       "Patches           1412\n",
       "Buttons/Pins      1370\n",
       "Hats               906\n",
       "Face Masks         732\n",
       "Stickers           655\n",
       "Tote Bags          433\n",
       "Towels              43\n",
       "Scarves             41\n",
       "Pants                3\n",
       "Name: New_Category_Level_4, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['New_Category_Level_4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Digital Music         764110\n",
       "Vinyl                 101878\n",
       "Not Merch              63187\n",
       "Shirt                  21955\n",
       "CD                     17796\n",
       "Other Items             9536\n",
       "Bundle                  4797\n",
       "Cassette                4597\n",
       "Poster/Print            2048\n",
       "Hoodie                  1673\n",
       "Patch                   1412\n",
       "Long-Sleeve Shirts      1373\n",
       "Buttons/Pins            1370\n",
       "Book                    1134\n",
       "Hats                     906\n",
       "Face Mask                732\n",
       "Sticker                  655\n",
       "Tote Bag                 433\n",
       "Tickets                  242\n",
       "Live Stream               71\n",
       "Towel                     43\n",
       "Scarves                   41\n",
       "Robes                      6\n",
       "Pants                      3\n",
       "Name: Merch_Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Merch_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Group by Artist Name and only show New_Category_Level 4 is 'T-Shirt' and do a describe on the Price Column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mArtist/Label Name\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39;49m\u001b[39mPaid (US Dollars)\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mdescribe()\u001b[39m.\u001b[39mloc[(df[\u001b[39m'\u001b[39m\u001b[39mNew_Category_Level_4\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mT-Shirt\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:605\u001b[0m, in \u001b[0;36mSeriesGroupBy.describe\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[39m@doc\u001b[39m(Series\u001b[39m.\u001b[39mdescribe)\n\u001b[0;32m    604\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescribe\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 605\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdescribe(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2694\u001b[0m, in \u001b[0;36mGroupBy.describe\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         result \u001b[39m=\u001b[39m described\u001b[39m.\u001b[39munstack()\n\u001b[0;32m   2692\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mto_frame()\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39miloc[:\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 2694\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(\n\u001b[0;32m   2695\u001b[0m     \u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mdescribe(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[0;32m   2696\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj,\n\u001b[0;32m   2697\u001b[0m     not_indexed_same\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   2698\u001b[0m )\n\u001b[0;32m   2699\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2700\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1629\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1592\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[0;32m   1594\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1599\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1600\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m   1601\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1602\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1629\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[0;32m   1630\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1631\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutated\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[0;32m    838\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[1;32m--> 839\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[0;32m    840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    841\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2695\u001b[0m, in \u001b[0;36mGroupBy.describe.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         result \u001b[39m=\u001b[39m described\u001b[39m.\u001b[39munstack()\n\u001b[0;32m   2692\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mto_frame()\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39miloc[:\u001b[39m0\u001b[39m]\n\u001b[0;32m   2694\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_apply_general(\n\u001b[1;32m-> 2695\u001b[0m     \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mdescribe(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[0;32m   2696\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selected_obj,\n\u001b[0;32m   2697\u001b[0m     not_indexed_same\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2698\u001b[0m )\n\u001b[0;32m   2699\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2700\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:10940\u001b[0m, in \u001b[0;36mNDFrame.describe\u001b[1;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[0;32m  10691\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m  10692\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescribe\u001b[39m(\n\u001b[0;32m  10693\u001b[0m     \u001b[39mself\u001b[39m: NDFrameT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10697\u001b[0m     datetime_is_numeric: bool_t \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m  10698\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m  10699\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  10700\u001b[0m \u001b[39m    Generate descriptive statistics.\u001b[39;00m\n\u001b[0;32m  10701\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10938\u001b[0m \u001b[39m    max            NaN      3.0\u001b[39;00m\n\u001b[0;32m  10939\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 10940\u001b[0m     \u001b[39mreturn\u001b[39;00m describe_ndframe(\n\u001b[0;32m  10941\u001b[0m         obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m  10942\u001b[0m         include\u001b[39m=\u001b[39;49minclude,\n\u001b[0;32m  10943\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m  10944\u001b[0m         datetime_is_numeric\u001b[39m=\u001b[39;49mdatetime_is_numeric,\n\u001b[0;32m  10945\u001b[0m         percentiles\u001b[39m=\u001b[39;49mpercentiles,\n\u001b[0;32m  10946\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\describe.py:101\u001b[0m, in \u001b[0;36mdescribe_ndframe\u001b[1;34m(obj, include, exclude, datetime_is_numeric, percentiles)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     describer \u001b[39m=\u001b[39m DataFrameDescriber(\n\u001b[0;32m     95\u001b[0m         obj\u001b[39m=\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m, obj),\n\u001b[0;32m     96\u001b[0m         include\u001b[39m=\u001b[39minclude,\n\u001b[0;32m     97\u001b[0m         exclude\u001b[39m=\u001b[39mexclude,\n\u001b[0;32m     98\u001b[0m         datetime_is_numeric\u001b[39m=\u001b[39mdatetime_is_numeric,\n\u001b[0;32m     99\u001b[0m     )\n\u001b[1;32m--> 101\u001b[0m result \u001b[39m=\u001b[39m describer\u001b[39m.\u001b[39;49mdescribe(percentiles\u001b[39m=\u001b[39;49mpercentiles)\n\u001b[0;32m    102\u001b[0m \u001b[39mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\describe.py:141\u001b[0m, in \u001b[0;36mSeriesDescriber.describe\u001b[1;34m(self, percentiles)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescribe\u001b[39m(\u001b[39mself\u001b[39m, percentiles: Sequence[\u001b[39mfloat\u001b[39m] \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m    137\u001b[0m     describe_func \u001b[39m=\u001b[39m select_describe_func(\n\u001b[0;32m    138\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj,\n\u001b[0;32m    139\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatetime_is_numeric,\n\u001b[0;32m    140\u001b[0m     )\n\u001b[1;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m describe_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj, percentiles)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\describe.py:243\u001b[0m, in \u001b[0;36mdescribe_numeric_1d\u001b[1;34m(series, percentiles)\u001b[0m\n\u001b[0;32m    238\u001b[0m formatted_percentiles \u001b[39m=\u001b[39m format_percentiles(percentiles)\n\u001b[0;32m    240\u001b[0m stat_index \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m formatted_percentiles \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    241\u001b[0m d \u001b[39m=\u001b[39m (\n\u001b[0;32m    242\u001b[0m     [series\u001b[39m.\u001b[39mcount(), series\u001b[39m.\u001b[39mmean(), series\u001b[39m.\u001b[39mstd(), series\u001b[39m.\u001b[39mmin()]\n\u001b[1;32m--> 243\u001b[0m     \u001b[39m+\u001b[39m series\u001b[39m.\u001b[39;49mquantile(percentiles)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m    244\u001b[0m     \u001b[39m+\u001b[39m [series\u001b[39m.\u001b[39mmax()]\n\u001b[0;32m    245\u001b[0m )\n\u001b[0;32m    246\u001b[0m \u001b[39m# GH#48340 - always return float on non-complex numeric data\u001b[39;00m\n\u001b[0;32m    247\u001b[0m dtype: DtypeObj \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:2683\u001b[0m, in \u001b[0;36mSeries.quantile\u001b[1;34m(self, q, interpolation)\u001b[0m\n\u001b[0;32m   2679\u001b[0m \u001b[39m# We dispatch to DataFrame so that core.internals only has to worry\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m \u001b[39m#  about 2D cases.\u001b[39;00m\n\u001b[0;32m   2681\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m-> 2683\u001b[0m result \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mquantile(q\u001b[39m=\u001b[39;49mq, interpolation\u001b[39m=\u001b[39;49minterpolation, numeric_only\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m   2684\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   2685\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:11321\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[1;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[0;32m  11315\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m  11316\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid method: \u001b[39m\u001b[39m{\u001b[39;00mmethod\u001b[39m}\u001b[39;00m\u001b[39m. Method must be in \u001b[39m\u001b[39m{\u001b[39;00mvalid_method\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m  11317\u001b[0m     )\n\u001b[0;32m  11318\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msingle\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m  11319\u001b[0m     \u001b[39m# error: Argument \"qs\" to \"quantile\" of \"BlockManager\" has incompatible type\u001b[39;00m\n\u001b[0;32m  11320\u001b[0m     \u001b[39m# \"Index\"; expected \"Float64Index\"\u001b[39;00m\n\u001b[1;32m> 11321\u001b[0m     res \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mquantile(\n\u001b[0;32m  11322\u001b[0m         qs\u001b[39m=\u001b[39;49mq, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, interpolation\u001b[39m=\u001b[39;49minterpolation  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m  11323\u001b[0m     )\n\u001b[0;32m  11324\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m  11325\u001b[0m     valid_interpolation \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhigher\u001b[39m\u001b[39m\"\u001b[39m}\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1631\u001b[0m, in \u001b[0;36mBlockManager.quantile\u001b[1;34m(self, qs, axis, interpolation)\u001b[0m\n\u001b[0;32m   1628\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   1629\u001b[0m new_axes[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m Float64Index(qs)\n\u001b[1;32m-> 1631\u001b[0m blocks \u001b[39m=\u001b[39m [\n\u001b[0;32m   1632\u001b[0m     blk\u001b[39m.\u001b[39mquantile(axis\u001b[39m=\u001b[39maxis, qs\u001b[39m=\u001b[39mqs, interpolation\u001b[39m=\u001b[39minterpolation)\n\u001b[0;32m   1633\u001b[0m     \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[0;32m   1634\u001b[0m ]\n\u001b[0;32m   1636\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1632\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1628\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   1629\u001b[0m new_axes[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m Float64Index(qs)\n\u001b[0;32m   1631\u001b[0m blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m-> 1632\u001b[0m     blk\u001b[39m.\u001b[39;49mquantile(axis\u001b[39m=\u001b[39;49maxis, qs\u001b[39m=\u001b[39;49mqs, interpolation\u001b[39m=\u001b[39;49minterpolation)\n\u001b[0;32m   1633\u001b[0m     \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[0;32m   1634\u001b[0m ]\n\u001b[0;32m   1636\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1335\u001b[0m, in \u001b[0;36mBlock.quantile\u001b[1;34m(self, qs, interpolation, axis)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[39massert\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# only ever called this way\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m \u001b[39massert\u001b[39;00m is_list_like(qs)  \u001b[39m# caller is responsible for this\u001b[39;00m\n\u001b[1;32m-> 1335\u001b[0m result \u001b[39m=\u001b[39m quantile_compat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, np\u001b[39m.\u001b[39;49masarray(qs\u001b[39m.\u001b[39;49m_values), interpolation)\n\u001b[0;32m   1336\u001b[0m \u001b[39m# ensure_block_shape needed for cases where we start with EA and result\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[39m#  is ndarray, e.g. IntegerArray, SparseArray\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m result \u001b[39m=\u001b[39m ensure_block_shape(result, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:37\u001b[0m, in \u001b[0;36mquantile_compat\u001b[1;34m(values, qs, interpolation)\u001b[0m\n\u001b[0;32m     35\u001b[0m     fill_value \u001b[39m=\u001b[39m na_value_for_dtype(values\u001b[39m.\u001b[39mdtype, compat\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m quantile_with_mask(values, mask, fill_value, qs, interpolation)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39m_quantile(qs, interpolation)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:95\u001b[0m, in \u001b[0;36mquantile_with_mask\u001b[1;34m(values, mask, fill_value, qs, interpolation)\u001b[0m\n\u001b[0;32m     93\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(flat, \u001b[39mlen\u001b[39m(values))\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(values), \u001b[39mlen\u001b[39m(qs))\n\u001b[0;32m     94\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m _nanpercentile(\n\u001b[0;32m     96\u001b[0m         values,\n\u001b[0;32m     97\u001b[0m         qs \u001b[39m*\u001b[39;49m \u001b[39m100.0\u001b[39;49m,\n\u001b[0;32m     98\u001b[0m         na_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m     99\u001b[0m         mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    100\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:216\u001b[0m, in \u001b[0;36m_nanpercentile\u001b[1;34m(values, qs, na_value, mask, interpolation)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mpercentile(\n\u001b[0;32m    217\u001b[0m         values,\n\u001b[0;32m    218\u001b[0m         qs,\n\u001b[0;32m    219\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39m# error: No overload variant of \"percentile\" matches argument types\u001b[39;00m\n\u001b[0;32m    221\u001b[0m         \u001b[39m# \"ndarray[Any, Any]\", \"ndarray[Any, dtype[floating[_64Bit]]]\",\u001b[39;00m\n\u001b[0;32m    222\u001b[0m         \u001b[39m# \"int\", \"Dict[str, str]\"  [call-overload]\u001b[39;00m\n\u001b[0;32m    223\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{np_percentile_argname: interpolation},  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4166\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[0;32m   4164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[0;32m   4165\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPercentiles must be in the range [0, 100]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 4166\u001b[0m \u001b[39mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[0;32m   4167\u001b[0m     a, q, axis, out, overwrite_input, method, keepdims)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4424\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[0;32m   4416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4417\u001b[0m                         q,\n\u001b[0;32m   4418\u001b[0m                         axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4421\u001b[0m                         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   4422\u001b[0m                         keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   4423\u001b[0m     \u001b[39m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4424\u001b[0m     r, k \u001b[39m=\u001b[39m _ureduce(a,\n\u001b[0;32m   4425\u001b[0m                     func\u001b[39m=\u001b[39;49m_quantile_ureduce_func,\n\u001b[0;32m   4426\u001b[0m                     q\u001b[39m=\u001b[39;49mq,\n\u001b[0;32m   4427\u001b[0m                     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4428\u001b[0m                     out\u001b[39m=\u001b[39;49mout,\n\u001b[0;32m   4429\u001b[0m                     overwrite_input\u001b[39m=\u001b[39;49moverwrite_input,\n\u001b[0;32m   4430\u001b[0m                     method\u001b[39m=\u001b[39;49mmethod)\n\u001b[0;32m   4431\u001b[0m     \u001b[39mif\u001b[39;00m keepdims:\n\u001b[0;32m   4432\u001b[0m         \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mreshape(q\u001b[39m.\u001b[39mshape \u001b[39m+\u001b[39m k)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3725\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3722\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3723\u001b[0m     keepdim \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m a\u001b[39m.\u001b[39mndim\n\u001b[1;32m-> 3725\u001b[0m r \u001b[39m=\u001b[39m func(a, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   3726\u001b[0m \u001b[39mreturn\u001b[39;00m r, keepdim\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4593\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4591\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4592\u001b[0m         arr \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m-> 4593\u001b[0m result \u001b[39m=\u001b[39m _quantile(arr,\n\u001b[0;32m   4594\u001b[0m                    quantiles\u001b[39m=\u001b[39;49mq,\n\u001b[0;32m   4595\u001b[0m                    axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4596\u001b[0m                    method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   4597\u001b[0m                    out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m   4598\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4691\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[0;32m   4687\u001b[0m previous_indexes, next_indexes \u001b[39m=\u001b[39m _get_indexes(arr,\n\u001b[0;32m   4688\u001b[0m                                               virtual_indexes,\n\u001b[0;32m   4689\u001b[0m                                               values_count)\n\u001b[0;32m   4690\u001b[0m \u001b[39m# --- Sorting\u001b[39;00m\n\u001b[1;32m-> 4691\u001b[0m arr\u001b[39m.\u001b[39;49mpartition(\n\u001b[0;32m   4692\u001b[0m     np\u001b[39m.\u001b[39;49munique(np\u001b[39m.\u001b[39;49mconcatenate(([\u001b[39m0\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[0;32m   4693\u001b[0m                               previous_indexes\u001b[39m.\u001b[39;49mravel(),\n\u001b[0;32m   4694\u001b[0m                               next_indexes\u001b[39m.\u001b[39;49mravel(),\n\u001b[0;32m   4695\u001b[0m                               ))),\n\u001b[0;32m   4696\u001b[0m     axis\u001b[39m=\u001b[39;49mDATA_AXIS)\n\u001b[0;32m   4697\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minexact):\n\u001b[0;32m   4698\u001b[0m     slices_having_nans \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(\n\u001b[0;32m   4699\u001b[0m         take(arr, indices\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis\u001b[39m=\u001b[39mDATA_AXIS)\n\u001b[0;32m   4700\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Group by Artist Name and only show New_Category_Level 4 is 'T-Shirt' and do a describe on the Price Column\n",
    "df.groupby('Artist/Label Name')['Paid (US Dollars)'].describe().loc[(df['New_Category_Level_4'] == 'T-Shirt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only Run When Ready to Export for Tableau\n",
    "# df.to_csv('After_Python_Processing_bandcamp_million_sales.csv', header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Exchange Rate Conversion\n",
    "\n",
    "This can be tabled for now as we can just focus on US Dollar Transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pandas as pd\n",
    "\n",
    "# # # create a sample table with some transactions\n",
    "# # data = {\n",
    "# #     \"Seller Currency\": [\"EUR\", \"GBP\", \"CAD\", \"JPY\"],\n",
    "# #     \"Price (Seller Currency)\": [100, 50, 75, 10000],\n",
    "# #     \"Date_Time_PT\": [\"2022-03-30 10:00:00\", \"2022-03-30 11:00:00\", \"2022-03-29 12:00:00\", \"2022-03-29 13:00:00\"],\n",
    "# # }\n",
    "# # test_df = pd.DataFrame(data)\n",
    "\n",
    "# # Convert Date_Time_Pt to datetime\n",
    "# test_df['Date_Time_PT'] = pd.to_datetime(test_df['Date_Time_PT'])\n",
    "\n",
    "# import requests\n",
    "\n",
    "# def get_exchange_rate(base_currency, target_currency, date):\n",
    "#     api_url = f\"https://api.exchangeratesapi.io/{date}\"\n",
    "#     response = requests.get(api_url, params={\"base\": base_currency, \"symbols\": target_currency})\n",
    "#     if response.status_code == 200:\n",
    "#         data = response.json()\n",
    "#         if target_currency in data[\"rates\"]:\n",
    "#             return data[\"rates\"][target_currency]\n",
    "#     return None\n",
    "\n",
    "# def convert_to_usd(row):\n",
    "#     base_currency = row[\"Seller Currency\"]\n",
    "#     seller_price = row[\"Price (Seller Currency)\"]\n",
    "#     exchange_date = row[\"Date_Time_PT\"].strftime(\"%Y-%m-%d\")\n",
    "#     exchange_rate = get_exchange_rate(base_currency, \"USD\", exchange_date)\n",
    "#     if exchange_rate is not None:\n",
    "#         return seller_price / exchange_rate\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # apply the function to create a new column with USD prices\n",
    "# test_df[\"Price_USD\"] = test_df.apply(convert_to_usd, axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de49e0496e93ae9d6470fd68773207095eefbd171a41b7294c60017eb55c8600"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
