{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Downloaded From: https://www.kaggle.com/datasets/mathurinache/1000000-bandcamp-sales\n",
    "\n",
    "# Importing Numerical Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option('display.max_row', None)\n",
    "pd.set_option('display.max_column', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Importing Visualization Packages\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# For Handling Times\n",
    "import pytz\n",
    "\n",
    "# Importing CSV\n",
    "df = pd.read_csv(r'C:\\Users\\nickb\\Documents\\SeattleU\\Fall 2022\\DataVisualization_BUAN5210\\Final Project\\1000000-bandcamp-sales.csv')\n",
    "\n",
    "# Replacing Item Names (can do this as Aliasing in Tableau too)\n",
    "replace_item_type = {'a': 'Digital Album',\n",
    "'p': 'Physical Item',\n",
    "'t': 'Digital Track'}\n",
    "df = df.replace({\"item_type\": replace_item_type})\n",
    "\n",
    "# Renamed for Clarity\n",
    "df.rename(columns = {'country':'Buyer Country',\n",
    "                     'releases':'Total Artist Releases'}, inplace = True)\n",
    "\n",
    "# Dropping Duplicate or Irrelevant Columns for Analysis\n",
    "df.drop('track_album_slug_text', axis=1, inplace=True)\n",
    "df.drop('country_code', axis=1, inplace=True)\n",
    "df.drop(['art_id'], axis=1, inplace=True)\n",
    "df.drop(['_id', 'art_url'], axis=1, inplace=True)\n",
    "df.drop(['url'], axis=1, inplace=True)\n",
    "\n",
    "# Dropping Irrelevant Columns or Columns With Too Many Missing Values\n",
    "df.drop(['package_image_id', 'Total Artist Releases','item_slug'], axis=1, inplace=True)\n",
    "\n",
    "# Replacing Item Names (can do this as Aliasing in Tableau too)\n",
    "df['slug_type'].replace('t', 'Digital Track', inplace=True)\n",
    "df['slug_type'].replace('a', 'Digital & Physical Albums', inplace=True)\n",
    "df['slug_type'].replace('p', 'Physical Merchandise', inplace=True)\n",
    "\n",
    "# This is how I found out that b is equal to 'Full Digital Discography'. Same Descriptions more or less. Uncomment to run if you're curious.\n",
    "# full_dig = df.loc[(df['item_type'] == 'b')]\n",
    "# full_dig['item_description'].value_counts()\n",
    "\n",
    "# Imputting Value for 'Full Digital Discography'\n",
    "df.loc[(df['item_type'] == 'b'), 'item_type'] = 'Full Digital Discography'\n",
    "\n",
    "# Imputting Value for Physical Album\n",
    "df.loc[(df['item_type'] != 'Digital Album') & (df['slug_type'] == 'Digital & Physical Albums'), 'item_type'] = 'Physical Album'\n",
    "\n",
    "# Creating (Hopefully) Clearer Feature Names\n",
    "df.rename(columns={'amount_paid_fmt': 'Currency Symbol + Paid (In Seller Currency)',\n",
    "                   'item_price': 'Price (Seller Currency)',\n",
    "                   'amount_paid': 'Paid (Seller Currency)',\n",
    "                   'amount_paid_usd': 'Paid (US Dollars)',\n",
    "                   'slug_type': 'Item Category (Main)',\n",
    "                   'item_type': 'Item Category (Subcategory)',\n",
    "                   'amount_over_fmt': 'Paid OVER List Price (Seller Currency)',\n",
    "                   'artist_name': 'Artist/Label Name'\n",
    "                   }, inplace=True)\n",
    "\n",
    "# Asessing if Item listed for free\n",
    "def no_price (value):\n",
    "   if value == float('inf'): \n",
    "      return 'Yes' # Done as Yes/No since it doesn't auto turn this into a numerical measure\n",
    "   return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item Listed As Free\n",
       "No     879253\n",
       "Yes    120747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Epoch Time to Time\n",
    "df['utc_date'] = pd.to_datetime(df['utc_date'],unit='s')\n",
    "\n",
    "# Converting Time to Pacific (Timezone Bandcamp Uses For Bandcamp Fridays)\n",
    "df['utc_date'] = df['utc_date'].dt.tz_localize('US/Pacific').dt.tz_convert('UTC')\n",
    "\n",
    "# Renaming Date as it's now Pacific Timezone\n",
    "df = df.rename({'utc_date': 'Date_Time_PT',}, axis=1) \n",
    "\n",
    "# Creating New Column for the Percentage a Buyer Paid Over the Seller's List Price on an Item\n",
    "df['Percent Paid Over List Price'] = ((df['Paid (Seller Currency)'] - df['Price (Seller Currency)']) / df['Price (Seller Currency)']) * 100\n",
    "\n",
    "# Creating a New Colunmn to Denote if an item is listed as free.\n",
    "def no_price (value):\n",
    "   if value == float('inf'): \n",
    "      return 'Yes' # Done as Yes/No since it doesn't auto turn this into a numerical measure\n",
    "   return 'No'\n",
    "\n",
    "df['Item Listed As Free'] = df['Percent Paid Over List Price'].map(no_price)\n",
    "\n",
    "df['Item Listed As Free'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item Category (Subcategory)</th>\n",
       "      <th>Date_Time_PT</th>\n",
       "      <th>Buyer Country</th>\n",
       "      <th>Item Category (Main)</th>\n",
       "      <th>Currency Symbol + Paid (In Seller Currency)</th>\n",
       "      <th>Price (Seller Currency)</th>\n",
       "      <th>item_description</th>\n",
       "      <th>Paid (Seller Currency)</th>\n",
       "      <th>Artist/Label Name</th>\n",
       "      <th>currency</th>\n",
       "      <th>Release Title</th>\n",
       "      <th>Paid (US Dollars)</th>\n",
       "      <th>Paid OVER List Price (Seller Currency)</th>\n",
       "      <th>addl_count</th>\n",
       "      <th>Percent Paid Over List Price</th>\n",
       "      <th>Item Listed As Free</th>\n",
       "      <th>Bandcamp_Friday?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital Album</td>\n",
       "      <td>2020-09-10 05:00:03.517499904+00:00</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Digital &amp; Physical Albums</td>\n",
       "      <td>$9.99</td>\n",
       "      <td>9.990</td>\n",
       "      <td>Live at Vicar Street</td>\n",
       "      <td>9.990</td>\n",
       "      <td>Girl Band</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.990</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item Category (Subcategory)                        Date_Time_PT  \\\n",
       "0               Digital Album 2020-09-10 05:00:03.517499904+00:00   \n",
       "\n",
       "    Buyer Country       Item Category (Main)  \\\n",
       "0  United Kingdom  Digital & Physical Albums   \n",
       "\n",
       "  Currency Symbol + Paid (In Seller Currency)  Price (Seller Currency)  \\\n",
       "0                                       $9.99                    9.990   \n",
       "\n",
       "       item_description  Paid (Seller Currency) Artist/Label Name currency  \\\n",
       "0  Live at Vicar Street                   9.990         Girl Band      USD   \n",
       "\n",
       "  Release Title  Paid (US Dollars)  Paid OVER List Price (Seller Currency)  \\\n",
       "0           NaN              9.990                                   0.000   \n",
       "\n",
       "   addl_count  Percent Paid Over List Price Item Listed As Free  \\\n",
       "0         NaN                         0.000                  No   \n",
       "\n",
       "  Bandcamp_Friday?  \n",
       "0               No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Over 100k of items had isna for paid over list price item, so recalculating colum. Uncomment next line to see.\n",
    "# df['Paid OVER List Price (Seller Currency)'].isna().value_counts()\n",
    "df['Paid OVER List Price (Seller Currency)'] = (df['Paid (Seller Currency)'] - df['Price (Seller Currency)'])\n",
    "\n",
    "# Rounding to Two Decimal Places, it seemed like some columns were not binning values correctly\n",
    "df['Paid OVER List Price (Seller Currency)'] = df['Paid OVER List Price (Seller Currency)'].round(decimals = 2)\n",
    "\n",
    "# Replace all the NaN Values which based on other columns can tell are 'Full Digital Discography\" with that\n",
    "df['Item Category (Main)'] = df['Item Category (Main)'].replace(np.NaN,'Full Digital Discography')\n",
    "\n",
    "# Gave More Accurate Name. There are EP's & Singles Shown Too.\n",
    "df.rename(columns={'album_title': 'Release Title'\n",
    "                   }, inplace=True)\n",
    "\n",
    "df['Percent Paid Over List Price'] = df['Percent Paid Over List Price'].round(decimals = 2)\n",
    "\n",
    "# Replacing Inifinite Values with NaN. This Way in Tableau, It Shows Datatype as Numeric\n",
    "df['Percent Paid Over List Price'] = df['Percent Paid Over List Price'].replace(np.inf, np.NaN)\n",
    "\n",
    "df['Bandcamp_Friday?'] = df['Date_Time_PT']\n",
    "# If on this date, then assign as Bandcamp Friday\n",
    "df.loc[(df['Date_Time_PT'] > '2020-10-02', \"Bandcamp_Friday?\")] = \"Yes\"\n",
    "\n",
    "# If on this date, then assign as NOT Bandcamp Friday\n",
    "df.loc[(df['Date_Time_PT'] < '2020-10-02', \"Bandcamp_Friday?\")] = \"No\"\n",
    "\n",
    "\n",
    "df.head(1)\n",
    "\n",
    "# Only Run When Ready to Export for Tableau\n",
    "# df.to_csv('bandcamp_million_sales_After_Python_Modifications_2.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on Discogs Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (InvalidAccessKeyId) when calling the ListBuckets operation: The AWS Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m s3 \u001b[39m=\u001b[39m boto3\u001b[39m.\u001b[39mclient(\u001b[39m'\u001b[39m\u001b[39ms3\u001b[39m\u001b[39m'\u001b[39m, aws_access_key_id\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m534296536076\u001b[39m\u001b[39m'\u001b[39m, aws_secret_access_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mShrek666!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# List all the buckets\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m buckets \u001b[39m=\u001b[39m s3\u001b[39m.\u001b[39;49mlist_buckets()\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m bucket \u001b[39min\u001b[39;00m buckets[\u001b[39m'\u001b[39m\u001b[39mBuckets\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(bucket[\u001b[39m'\u001b[39m\u001b[39mName\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\envs\\bandcamp_merch\\Lib\\site-packages\\botocore\\client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    532\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    534\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\envs\\bandcamp_merch\\Lib\\site-packages\\botocore\\client.py:980\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    978\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    979\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (InvalidAccessKeyId) when calling the ListBuckets operation: The AWS Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "# import boto3\n",
    "\n",
    "# # Setup boto3 client\n",
    "# s3 = boto3.client('s3', aws_access_key_id='534296536076', aws_secret_access_key='Shrek666!')\n",
    "\n",
    "# # List all the buckets\n",
    "# buckets = s3.list_buckets()\n",
    "# for bucket in buckets['Buckets']:\n",
    "#     print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'<?')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m         print_element(child, level \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[39m# Iterate and print the XML content\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfor\u001b[39;00m event, elem \u001b[39min\u001b[39;00m context:\n\u001b[0;32m     42\u001b[0m     print_element(elem)\n\u001b[0;32m     43\u001b[0m     elem\u001b[39m.\u001b[39mclear()\n",
      "File \u001b[1;32msrc\\lxml\\iterparse.pxi:210\u001b[0m, in \u001b[0;36mlxml.etree.iterparse.__next__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\iterparse.pxi:195\u001b[0m, in \u001b[0;36mlxml.etree.iterparse.__next__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\lxml\\iterparse.pxi:220\u001b[0m, in \u001b[0;36mlxml.etree.iterparse._read_more_events\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\envs\\bandcamp_merch\\Lib\\gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39merrno\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(errno\u001b[39m.\u001b[39mEBADF, \u001b[39m\"\u001b[39m\u001b[39mread() on write-only GzipFile object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 301\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mread(size)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\envs\\bandcamp_merch\\Lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b) \u001b[39mas\u001b[39;00m view, view\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m(byte_view))\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\envs\\bandcamp_merch\\Lib\\gzip.py:499\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_member:\n\u001b[0;32m    496\u001b[0m     \u001b[39m# If the _new_member flag is set, we have to\u001b[39;00m\n\u001b[0;32m    497\u001b[0m     \u001b[39m# jump to the next member, if there is one.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_read()\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_gzip_header():\n\u001b[0;32m    500\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos\n\u001b[0;32m    501\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\envs\\bandcamp_merch\\Lib\\gzip.py:468\u001b[0m, in \u001b[0;36m_GzipReader._read_gzip_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_gzip_header\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 468\u001b[0m     last_mtime \u001b[39m=\u001b[39m _read_gzip_header(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp)\n\u001b[0;32m    469\u001b[0m     \u001b[39mif\u001b[39;00m last_mtime \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nickb\\anaconda3\\envs\\bandcamp_merch\\Lib\\gzip.py:428\u001b[0m, in \u001b[0;36m_read_gzip_header\u001b[1;34m(fp)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m magic \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\037\u001b[39;00m\u001b[39m\\213\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 428\u001b[0m     \u001b[39mraise\u001b[39;00m BadGzipFile(\u001b[39m'\u001b[39m\u001b[39mNot a gzipped file (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m magic)\n\u001b[0;32m    430\u001b[0m (method, flag, last_mtime) \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m<BBIxx\u001b[39m\u001b[39m\"\u001b[39m, _read_exact(fp, \u001b[39m8\u001b[39m))\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m!=\u001b[39m \u001b[39m8\u001b[39m:\n",
      "\u001b[1;31mBadGzipFile\u001b[0m: Not a gzipped file (b'<?')"
     ]
    }
   ],
   "source": [
    "# import boto3\n",
    "# import requests\n",
    "# from lxml import etree\n",
    "# import pandas as pd\n",
    "# import gzip\n",
    "# from io import BytesIO\n",
    "\n",
    "# # Define the S3 bucket and file path\n",
    "# bucket = 'discogs-data-dumps'\n",
    "# key = 'data/2022/discogs_20221201_releases.xml.gz'\n",
    "\n",
    "# # Create a session using your AWS credentials\n",
    "# s3 = boto3.client('s3', aws_access_key_id='534296536076', aws_secret_access_key='Shrek666!')\n",
    "\n",
    "# # Generate the URL to get 'key-name' from 'bucket-name'\n",
    "# url = s3.generate_presigned_url(\n",
    "#     ClientMethod='get_object',\n",
    "#     Params={\n",
    "#         'Bucket': bucket,\n",
    "#         'Key': key\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # Fetch the content using the generated URL\n",
    "# response = requests.get(url)\n",
    "\n",
    "# # Decompress the Gzip content\n",
    "# gzip_file = BytesIO(response.content)\n",
    "# with gzip.GzipFile(fileobj=gzip_file) as uncompressed_file:\n",
    "#     # Parse the uncompressed content\n",
    "#     context = etree.iterparse(uncompressed_file, events=('end',), tag='release')\n",
    "\n",
    "#     # Recursive function to print XML elements and their attributes\n",
    "#     def print_element(e, level=0):\n",
    "#         indent = '  ' * level\n",
    "#         print(f\"{indent}Tag: {e.tag}, Attributes: {e.attrib}\")\n",
    "#         for child in e:\n",
    "#             print_element(child, level + 1)\n",
    "\n",
    "#     # Iterate and print the XML content\n",
    "#     for event, elem in context:\n",
    "#         print_element(elem)\n",
    "#         elem.clear()\n",
    "#         while elem.getprevious() is not None:\n",
    "#             del elem.getparent()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxml.etree.iterparse at 0x1a4ef985ee0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_element(e, level=0):\n",
    "    indent = '  ' * level\n",
    "    print(f\"{indent}Tag: {e.tag}, Attributes: {e.attrib}\")\n",
    "    for child in e:\n",
    "        print_element(child, level + 1)\n",
    "\n",
    "for event, elem in context:\n",
    "    print_element(elem)\n",
    "    elem.clear()\n",
    "    while elem.getprevious() is not None:\n",
    "        del elem.getparent()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f54dced06304130cb951df2aee7df93dacfbf7e633c0fd529e7a54b52d93e61f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
